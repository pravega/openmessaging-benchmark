{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install p3_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import json\n",
    "from io import StringIO\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p3_data\n",
    "from p3_data import (glob_file_list , load_json_from_file, merge_dicts, plot_groups, \n",
    "    get_varying_column_names, filter_dataframe, take_varying_columns,\n",
    "    load_json_records_as_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_files = []\n",
    "src_files += ['../data/p3_test_driver/results/json/*.json']\n",
    "raw_df = load_json_records_as_dataframe(src=src_files, ignore_error=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_result(result):\n",
    "    try:\n",
    "        r = result.copy()\n",
    "        r['driverName'] = r['driver']['name']\n",
    "        if r['driverName'] == 'Pulsar':\n",
    "            r = merge_dicts(r, r['driver']['client']['persistence'])\n",
    "        r = merge_dicts(r, r['workload'])\n",
    "        del r['workload']\n",
    "        r = merge_dicts(r, r['omb_results'])\n",
    "        for k in list(r.keys()):\n",
    "            if 'Quantiles' in k:\n",
    "                r[k] = pd.Series(data=[float(q) for q in r[k].keys()], index=list(r[k].values())).sort_index() / 100\n",
    "            elif isinstance(r[k], list) and 'Rate' in k:\n",
    "                r[k] = pd.Series(r[k])\n",
    "                r['%sMean' % k] = r[k].mean()\n",
    "        r['numWorkloadWorkers'] = int(r.get('numWorkers', 0))\n",
    "        r['throttleEventsPerSec'] = r['producerRate']\n",
    "        r['publishRateEventsPerSecMean'] = r['publishRateMean']\n",
    "        r['publishRateMBPerSecMean'] = r['publishRateMean'] * r['messageSize'] * 1e-6\n",
    "        r['publishLatencyMsAvg'] = r['aggregatedPublishLatencyAvg']\n",
    "        r['publishLatencyMs99Pct'] = r['aggregatedPublishLatency99pct']\n",
    "        r['endToEndLatencyMsAvg'] = r['aggregatedEndToEndLatencyAvg']\n",
    "        r['endToEndLatencyMs99Pct'] = r['aggregatedEndToEndLatency99pct']\n",
    "        return pd.Series(r)\n",
    "    except Exception as e:\n",
    "        print('ERROR: %s: %s' % (r['test_uuid'], e))\n",
    "r = clean_result(raw_df.iloc[0])\n",
    "pd.DataFrame(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = raw_df.apply(clean_result, axis=1)\n",
    "clean_df = clean_df.set_index('test_uuid', drop=False)\n",
    "clean_df = clean_df[clean_df.error==False]\n",
    "clean_df = clean_df.sort_values(['utc_begin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_cols = [\n",
    "    'numWorkers',\n",
    "    'topics',\n",
    "    'partitionsPerTopic',\n",
    "    'producersPerTopic',\n",
    "    'subscriptionsPerTopic',\n",
    "    'consumerPerSubscription',\n",
    "    'testDurationMinutes',\n",
    "    'keyDistributor',\n",
    "    'git_commit',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'messageSize',\n",
    "    'numWorkloadWorkers',\n",
    "    'producersPerTopic',\n",
    "    'partitionsPerTopic',\n",
    "    'testDurationMinutes',\n",
    "    'subscriptionsPerTopic',\n",
    "    'consumerPerSubscription',\n",
    "    'ackQuorum',\n",
    "    'throttleEventsPerSec',\n",
    "    #'deduplicationEnabled',\n",
    "    'publishRateEventsPerSecMean',\n",
    "    'publishRateMBPerSecMean',\n",
    "    'publishLatencyMsAvg',\n",
    "    'publishLatencyMs99Pct',\n",
    "    'endToEndLatencyMsAvg',\n",
    "    'endToEndLatencyMs99Pct',\n",
    "    'utc_begin',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[cols].tail(2).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean_df[cols].to_csv('openmessaging-benchmark-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_df[cols]\n",
    "df = df.sort_values(['messageSize','numWorkloadWorkers','producersPerTopic','throttleEventsPerSec','utc_begin'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messageSize = 10000\n",
    "filt_df = filter_dataframe(\n",
    "    clean_df,\n",
    "    driverName='Pulsar',\n",
    "    messageSize=messageSize, \n",
    "#     producerRate=5e4,\n",
    "    numWorkloadWorkers=4, \n",
    "    producersPerTopic=4,\n",
    "    partitionsPerTopic=16,\n",
    "    deduplicationEnabled=True,\n",
    "    testDurationMinutes=5,    \n",
    ")\n",
    "filt_df[cols].sort_values(['publishRateMBPerSecMean'], ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "take_varying_columns(filt_df[cols]).sort_values(['endToEndLatencyMs99Pct'], ascending=True).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = (filt_df\n",
    "    .set_index(['publishRateMBPerSecMean'])\n",
    "    .sort_index()\n",
    "    [[\n",
    "        'aggregatedPublishLatency50pct',\n",
    "        'aggregatedPublishLatency95pct',\n",
    "        'aggregatedPublishLatency99pct',\n",
    "        'aggregatedEndToEndLatency50pct',\n",
    "        'aggregatedEndToEndLatency95pct',\n",
    "        'aggregatedEndToEndLatency99pct',\n",
    "        'test_uuid',\n",
    "    ]]\n",
    "    .rename(columns=dict(\n",
    "        aggregatedPublishLatency50pct='Publish Latency p50',\n",
    "        aggregatedPublishLatency95pct='Publish Latency p95',\n",
    "        aggregatedPublishLatency99pct='Publish Latency p99',\n",
    "        aggregatedEndToEndLatency50pct='E2E Latency p50',\n",
    "        aggregatedEndToEndLatency95pct='E2E Latency p95',\n",
    "        aggregatedEndToEndLatency99pct='E2E Latency p99',\n",
    "    ))\n",
    "    )\n",
    "plot_df.index.name = 'Publish Throughput (MB/s)'\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Message Size %d' % (messageSize)\n",
    "ax = plot_df.plot(\n",
    "    logx=True, \n",
    "    logy=True,\n",
    "    figsize=(10,8), \n",
    "    grid=True, \n",
    "    title=title, \n",
    "    style=['x:b','x-.b','x-b','+:r','+-.r','+-r'])\n",
    "ax.set_ylabel('Latency (ms)');\n",
    "tick_formatter = matplotlib.ticker.LogFormatter()\n",
    "ax.xaxis.set_major_formatter(tick_formatter)\n",
    "ax.yaxis.set_major_formatter(tick_formatter)\n",
    "ax.grid('on', which='both', axis='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_df[info_cols].drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_groups(\n",
    "#     filt_df, \n",
    "#     x_col='publishRateEventsPerSecMean',\n",
    "#     y_col='publishLatencyMs99Pct',\n",
    "#     group_by_columns=['partitionsPerTopic', 'messageSize'],\n",
    "#     semilogx=True,\n",
    "# #     ylim=[0,100],\n",
    "# );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Latency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_df\n",
    "df = df[df.test_uuid=='f6030c7e-0bd4-49c9-8448-d3ca9458e9e4']\n",
    "t = df.iloc[0]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Distribution Function\n",
    "pubcdf = t.aggregatedPublishLatencyQuantiles\n",
    "pubcdf.name = 'Publish Latency CDF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Probability Distribution Function (latency histogram)\n",
    "pubpdf = pd.Series(index=pubcdf.index, data=np.gradient(pubcdf, pubcdf.index.values), name='Publish Latency PDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0, ax0 = plt.subplots()\n",
    "ax1 = ax0.twinx()\n",
    "pubpdf.plot(ax=ax0, xlim=[1,100], ylim=[0,None], style='r', title='Publish Latency PDF and CDF')\n",
    "pubcdf.plot(ax=ax1, xlim=[1,100], secondary_y=True, logx=True, ylim=[0,1])\n",
    "# ax0.set_ylabel('PDF');\n",
    "# ax1.set_ylabel('CDF');\n",
    "ax0.set_xlabel('Publish Latency (ms)');\n",
    "tick_formatter = matplotlib.ticker.LogFormatter()\n",
    "ax0.xaxis.set_major_formatter(tick_formatter)\n",
    "ax0.grid('on', which='both', axis='both')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative Distribution Function\n",
    "e2ecdf = t.aggregatedEndToEndLatencyQuantiles\n",
    "e2ecdf.name = 'E2E Latency CDF'\n",
    "# Probability Distribution Function (latency histogram)\n",
    "e2epdf = pd.Series(index=e2ecdf.index, data=np.gradient(e2ecdf, e2ecdf.index.values), name='E2E Latency PDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0, ax0 = plt.subplots()\n",
    "ax1 = ax0.twinx()\n",
    "e2epdf.plot(ax=ax0, xlim=[1,100], ylim=[0,None], style='r', title='E2E Latency PDF and CDF')\n",
    "e2ecdf.plot(ax=ax1, xlim=[1,100], secondary_y=True, logx=True, ylim=[0,1])\n",
    "# ax0.set_ylabel('PDF');\n",
    "# ax1.set_ylabel('CDF');\n",
    "ax0.set_xlabel('E2E Latency (ms)');\n",
    "tick_formatter = matplotlib.ticker.LogFormatter()\n",
    "ax0.xaxis.set_major_formatter(tick_formatter)\n",
    "ax0.grid('on', which='both', axis='both')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0, ax0 = plt.subplots()\n",
    "xlim=[1,25]\n",
    "pubcdf.plot(ax=ax0, xlim=xlim, logx=True, ylim=[0,1], legend=True, figsize=(10,8))\n",
    "e2ecdf.plot(ax=ax0, xlim=xlim, logx=True, ylim=[0,1], legend=True)\n",
    "ax0.set_xlabel('E2E Latency (ms)');\n",
    "tick_formatter = matplotlib.ticker.LogFormatter()\n",
    "ax0.xaxis.set_major_formatter(tick_formatter)\n",
    "ax0.grid('on', which='both', axis='both')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
