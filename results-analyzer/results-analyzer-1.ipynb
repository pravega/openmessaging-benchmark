{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.cm as cm\n",
    "import seaborn as sns\n",
    "import json\n",
    "from io import StringIO\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import molten_data_common_lib\n",
    "importlib.reload(molten_data_common_lib)\n",
    "from molten_data_common_lib import glob_file_list , load_json_from_file, merge_dicts, plot_groups, get_varying_column_names, filter_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_files = []\n",
    "src_files += ['../p3_test_driver/logs/workload-*.json']\n",
    "filenames = glob_file_list(src_files)\n",
    "print('Loading records from %d files...' % len(filenames))\n",
    "raw_results = [load_json_from_file(filename) for filename in filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.DataFrame(raw_results)\n",
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_result(result):\n",
    "    r = result.copy()\n",
    "    workload = json.load(StringIO(r['workload']))\n",
    "    r = merge_dicts(r, workload)\n",
    "    r = merge_dicts(r, r['workload'])\n",
    "    del r['workload']\n",
    "    r['driverName'] = r['driver']['name']\n",
    "    del r['driver']\n",
    "    for k in list(r.keys()):\n",
    "        if 'Quantiles' in k:\n",
    "            r[k] = pd.Series(data=[float(q) for q in r[k].keys()], index=list(r[k].values()))\n",
    "        elif isinstance(r[k], list):\n",
    "            r[k] = pd.Series(r[k])\n",
    "            r['%sMean' % k] = r[k].mean()\n",
    "    r['numWorkloadWorkers'] = int(r.get('numWorkers', 0))\n",
    "    r['throttleEventsPerSec'] = r['producerRate']\n",
    "    r['publishRateEventsPerSecMean'] = r['publishRateMean']\n",
    "    r['publishRateMBPerSecMean'] = r['publishRateMean'] * r['messageSize'] * 1e-6\n",
    "    r['publishLatencyMsAvg'] = r['aggregatedPublishLatencyAvg']\n",
    "    r['publishLatencyMs99Pct'] = r['aggregatedPublishLatency99pct']\n",
    "    r['endToEndLatencyMsAvg'] = r['aggregatedEndToEndLatencyAvg']\n",
    "    r['endToEndLatencyMs99Pct'] = r['aggregatedEndToEndLatency99pct']\n",
    "    return pd.Series(r)\n",
    "# r = clean_result(raw_results[0])\n",
    "# pd.DataFrame(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = raw_df.apply(clean_result, axis=1)\n",
    "clean_df = clean_df.sort_values(['utc_begin'])\n",
    "# clean_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_cols = [\n",
    "    'numWorkers',\n",
    "    'topics',\n",
    "    'partitionsPerTopic',\n",
    "    'producersPerTopic',\n",
    "    'subscriptionsPerTopic',\n",
    "    'consumerPerSubscription',\n",
    "    'testDurationMinutes',\n",
    "    'keyDistributor',\n",
    "    'git_commit',    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\n",
    "    'messageSize',\n",
    "    'numWorkloadWorkers',\n",
    "    'producersPerTopic',\n",
    "    'partitionsPerTopic',\n",
    "    'testDurationMinutes',\n",
    "    'subscriptionsPerTopic',\n",
    "    'throttleEventsPerSec',\n",
    "    'publishRateEventsPerSecMean',\n",
    "    'publishRateMBPerSecMean',\n",
    "    'publishLatencyMsAvg',\n",
    "    'publishLatencyMs99Pct',\n",
    "    'endToEndLatencyMsAvg',\n",
    "    'endToEndLatencyMs99Pct',\n",
    "    'utc_begin',\n",
    "    'test_uuid',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[cols].to_csv('openmessaging-benchmark-results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = clean_df[cols]\n",
    "#df = df.sort_values(['messageSize','numWorkloadWorkers','producersPerTopic','throttleEventsPerSec','utc_begin'])\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messageSize = 10000\n",
    "filt_df = filter_dataframe(\n",
    "    clean_df,\n",
    "    messageSize=messageSize, \n",
    "    numWorkloadWorkers=2, \n",
    "    partitionsPerTopic=16,\n",
    "    testDurationMinutes=15,\n",
    ")\n",
    "filt_df[cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df = (filt_df\n",
    "    .set_index(['publishRateEventsPerSecMean'])\n",
    "    .sort_index()\n",
    "    [[\n",
    "        'aggregatedPublishLatency50pct',\n",
    "        'aggregatedPublishLatency95pct',\n",
    "        'aggregatedPublishLatency99pct',\n",
    "        'aggregatedEndToEndLatency50pct',\n",
    "        'aggregatedEndToEndLatency95pct',\n",
    "        'aggregatedEndToEndLatency99pct',\n",
    "    ]]\n",
    "    .rename(columns=dict(\n",
    "        aggregatedPublishLatency50pct='Publish Latency p50',\n",
    "        aggregatedPublishLatency95pct='Publish Latency p95',\n",
    "        aggregatedPublishLatency99pct='Publish Latency p99',\n",
    "        aggregatedEndToEndLatency50pct='E2E Latency p50',\n",
    "        aggregatedEndToEndLatency95pct='E2E Latency p95',\n",
    "        aggregatedEndToEndLatency99pct='E2E Latency p99',\n",
    "    ))\n",
    "    )\n",
    "plot_df.index.name = 'Publish Throughput (events/s)'\n",
    "plot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = 'Message Size %d' % (messageSize)\n",
    "ax = plot_df.plot(    \n",
    "    logx=True, \n",
    "    logy=True,\n",
    "    figsize=(10,8), \n",
    "    grid=True, \n",
    "    title=title, \n",
    "    style=['x:b','x-.b','x-b','+:r','+-.r','+-r'])\n",
    "ax.set_ylabel('Latency (ms)');\n",
    "ax.xaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter(useOffset=False))\n",
    "ax.yaxis.set_major_formatter(matplotlib.ticker.ScalarFormatter(useOffset=False))\n",
    "ax.grid('on', which='both', axis='both')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_df[info_cols].drop_duplicates().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_groups(\n",
    "#     filt_df, \n",
    "#     x_col='publishRateEventsPerSecMean',\n",
    "#     y_col='publishLatencyMs99Pct',\n",
    "#     group_by_columns=['partitionsPerTopic', 'messageSize'],\n",
    "#     semilogx=True,\n",
    "# #     ylim=[0,100],\n",
    "# );"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Latency Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = clean_df\n",
    "df = df[df.test_uuid=='a073135e-b3ed-4b4b-8fc2-d449f427af23']\n",
    "t = df.iloc[0]\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = t.aggregatedPublishLatencyQuantiles\n",
    "cdf = cdf / 100\n",
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf.plot(logx=True, grid=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pd.Series(index=cdf.index, data=np.gradient(cdf, cdf.index.values))\n",
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf.plot(logx=True, logy=False, grid=True, xlim=[3,2000], ylim=[0,None]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0, ax0 = plt.subplots()\n",
    "ax1 = ax0.twinx()\n",
    "cdf.plot(ax=ax0, logx=True, ylim=[0,1])\n",
    "pdf.plot(secondary_y=True, ylim=[0,None], ax=ax1)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig0, ax0 = plt.subplots()\n",
    "ax0.plot(pdf.values, pdf.index.values)\n",
    "ax0.grid('on', which='both', axis='y')\n",
    "ax0.semilogy(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
